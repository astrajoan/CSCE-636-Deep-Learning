{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project10_demoApply_to_Video.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-YxXQkuMEa7"
      },
      "source": [
        "# Scraping and parsing from YouTube query"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Kev2GYZMLPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22b3a955-869a-44c5-98c6-4d22a0d92fdc"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# keywords = ['python', 'youtube', 'scraper']\n",
        "keywords = ['arranging flowers']\n",
        "pages = 5\n",
        "\n",
        "baseUrl = 'https://www.youtube.com'\n",
        "headMatch = '{\"responseContext\"'\n",
        "tailMatch = ';</script>'\n",
        "outputFile = open('output.csv', 'w')\n",
        "debugFile = open('debug.txt', 'w')\n",
        "outputLines = []\n",
        "\n",
        "for page in range(1, pages+1):\n",
        "    response = requests.get(baseUrl+'/results?search_query='+'+'.join(keywords)+'&page='+str(page))\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    debugFile.write(soup.prettify())\n",
        "    jsonStr = ''\n",
        "\n",
        "    for script in soup.find_all('script'):\n",
        "        scriptStr = str(script)\n",
        "        headIndex = scriptStr.find(headMatch)\n",
        "        if headIndex != -1:\n",
        "            tailIndex = scriptStr.find(tailMatch)\n",
        "            jsonStr = scriptStr[headIndex:tailIndex]\n",
        "            break\n",
        "\n",
        "    data = json.loads(jsonStr)\n",
        "    contents = data['contents']['twoColumnSearchResultsRenderer']['primaryContents']['sectionListRenderer']['contents'][0]['itemSectionRenderer']['contents']\n",
        "    for content in contents:\n",
        "        if 'videoRenderer' in content:\n",
        "            title = content['videoRenderer']['title']['runs'][0]['text'].replace(',', ' ')\n",
        "            url = content['videoRenderer']['navigationEndpoint']['commandMetadata']['webCommandMetadata']['url']\n",
        "            outputLines.append(title+','+baseUrl+url)\n",
        "\n",
        "outputFile.write('title,url\\n'+'\\n'.join(outputLines))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9620"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKZ04e91P-lQ"
      },
      "source": [
        "# Download youtube videos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCd5NcExQoOo"
      },
      "source": [
        "Make directory for the youtube videos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4IFB5hWK_h0"
      },
      "source": [
        "import os\n",
        "\n",
        "# Directory for the YouTube videos\n",
        "youtube_dir = '/content/youtube'\n",
        "os.mkdir(youtube_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoixdpR6QtCX"
      },
      "source": [
        "Download YouTube videos from scraped information"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wyi9nmSZ3x2",
        "outputId": "3bf6d5e1-30a7-46ac-a661-723eafc8b5c3"
      },
      "source": [
        "!pip install --upgrade youtube_dl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtube_dl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/93/3faf0e257fe2d37672901b46739bf63e198066e53dd02d956d6b2daa9c49/youtube_dl-2021.4.26-py2.py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 4.5MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2021.4.26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9J1KsvEQifb",
        "outputId": "c8a8ac16-95a2-4943-9a86-15a3db13281d"
      },
      "source": [
        "import youtube_dl, subprocess\n",
        "import datetime\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "'''\n",
        "  YouTube videos\n",
        "'''\n",
        "\n",
        "links = ['https://www.youtube.com/watch?v=qZOP4ZPkIAU',\n",
        "         ]\n",
        "for i, link in enumerate(links):\n",
        "  for j in range(0,60,2): # The range is number of seconds to test\n",
        "    URL = link # url of YouTube video\n",
        "    FROM = str(datetime.timedelta(seconds=j))\n",
        "    LENGTH = str(datetime.timedelta(seconds=2))\n",
        "    TARGET = os.path.join(youtube_dir,\"test.{}.mp4\".format(np.int(j/2)))\n",
        "    \n",
        "    with youtube_dl.YoutubeDL({'format': 'best'}) as ydl:\n",
        "      try:\n",
        "        result = ydl.extract_info(URL, download=False)\n",
        "        video = result['entries'][0] if 'entries' in result else result\n",
        "      except:\n",
        "        continue\n",
        "      \n",
        "    url = video['url']\n",
        "    subprocess.call(['ffmpeg', '-i', url, '-ss', FROM, '-t', LENGTH, \n",
        "                    '-c:v', 'copy', '-c:a', 'copy', TARGET,]) \n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[youtube] qZOP4ZPkIAU: Downloading webpage\n",
            "[youtube] qZOP4ZPkIAU: Downloading webpage\n",
            "[youtube] qZOP4ZPkIAU: Downloading webpage\n",
            "[youtube] qZOP4ZPkIAU: Downloading webpage\n",
            "[youtube] qZOP4ZPkIAU: Downloading webpage\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShhaHLnt-7gO"
      },
      "source": [
        "# Test on YouTube videos and write to .json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZPi5pDt-dK8"
      },
      "source": [
        "Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1apgDxAzUyDi"
      },
      "source": [
        "import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "test_model = load_model('plants_Inception_try.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGZJUtsE-f0E"
      },
      "source": [
        "Function for predicting whether clip contains target action and write to file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drSHX6cwV70u"
      },
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import json\n",
        "from time import sleep\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "img_rows, img_cols, img_depth = 112, 112, 25\n",
        "\n",
        "def load_video(path, max_frames=0, resize=(112, 112)):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "  try:\n",
        "    while True:\n",
        "      ret, frame = cap.read()\n",
        "      if frame is not None:\n",
        "        frame = cv2.resize(frame, resize)\n",
        "        frame = frame[:, :, [2, 1, 0]]\n",
        "        frames.append(frame)\n",
        "        # plt.imshow(frame) \n",
        "\n",
        "      else:\n",
        "        # print(\"Frame is None\")\n",
        "        break\n",
        "      \n",
        "      if len(frames) == max_frames:\n",
        "        break\n",
        "  finally:\n",
        "    cap.release()\n",
        "  return np.array(frames) / 255.0\n",
        "\n",
        "videos = []\n",
        "\n",
        "for i in range(30): # The number of clips downloaded to test\n",
        "  try:\n",
        "    frames = load_video('/content/youtube/test.{}.mp4'.format(i),max_frames=25)\n",
        "\n",
        "    frames = np.expand_dims(frames,axis=0)\n",
        "\n",
        "    p = test_model.predict(frames, batch_size = 1) # verbose = 1\n",
        "    # print(p)\n",
        "    prob = p[0][1]\n",
        "\n",
        "    if prob > 0.6:\n",
        "        temp = {\n",
        "            'videoID': \"qZOP4ZPkIAU\", # Change to video ID\n",
        "            'type': \"segment\",\n",
        "            'startTime': np.float(i*2),\n",
        "            'endTime': np.float((i+1)*2),\n",
        "            'observer': 'CSCE636Spring2021-astrajoan-10',\n",
        "            'isHuman': 'false',\n",
        "            'confirmedBySomeone': 'false',\n",
        "            'rejectedBySomeone': 'false',\n",
        "            'observation': {\n",
        "                'label': 'Arrange_flowers_or_water_plants_etc',\n",
        "                'labelConfidence': np.float(prob),\n",
        "            }\n",
        "        }\n",
        "\n",
        "        videos.append(temp)\n",
        "\n",
        "  except:\n",
        "    continue\n",
        "\n",
        "with open('1.json', 'w', encoding='utf-8') as f:\n",
        "  json.dump(videos, f, indent=4)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6WUzG92drZi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
